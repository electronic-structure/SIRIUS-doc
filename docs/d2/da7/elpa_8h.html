<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>SIRIUS: elpa.h File Reference</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js", "TeX/AMSmath.js", "TeX/AMSsymbols.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">SIRIUS
   &#160;<span id="projectnumber">5.9</span>
   </div>
   <div id="projectbrief">Electronic structure library and applications</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "../../search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('../../',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="../../dir_68267d1309a1af8e8297ef4c3efbcdba.html">src</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle">
<div class="title">elpa.h File Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>Interface to ELPA library.  
<a href="#details">More...</a></p>
<div class="textblock"><div id="dynsection-0" onclick="return toggleVisibility(this)" class="dynheader closed" style="cursor:pointer;">
  <img id="dynsection-0-trigger" src="../../closed.png" alt="+"/> This graph shows which files directly or indirectly include this file:</div>
<div id="dynsection-0-summary" class="dynsummary" style="display:block;">
</div>
<div id="dynsection-0-content" class="dyncontent" style="display:none;">
<div class="center"><div class="zoom"><iframe scrolling="no" frameborder="0" src="../../dd/deb/elpa_8h__dep__incl.svg" width="100%" height="600"><p><b>This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.</b></p></iframe></div></div>
</div>
</div>
<p><a href="../../d2/da7/elpa_8h_source.html">Go to the source code of this file.</a></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a350ad60d14a1858f99cf6825c5c3351a"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d2/da7/elpa_8h.html#a350ad60d14a1858f99cf6825c5c3351a">elpa_solve_evp_real_double</a> (int na, int nev, double *a, int lda, double *ev, double *q, int ldq, int nblk, int matrixCols, int mpi_comm_rows, int mpi_comm_cols, int mpi_comm_all, int THIS_REAL_ELPA_KERNEL_API, int useQR, int useGPU, char *method)</td></tr>
<tr class="memdesc:a350ad60d14a1858f99cf6825c5c3351a"><td class="mdescLeft">&#160;</td><td class="mdescRight">C interface to driver function "elpa_solve_evp_real_double".  <a href="#a350ad60d14a1858f99cf6825c5c3351a">More...</a><br /></td></tr>
<tr class="separator:a350ad60d14a1858f99cf6825c5c3351a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6333453aa7a2cc6735b96d0a421ed28b"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d2/da7/elpa_8h.html#a6333453aa7a2cc6735b96d0a421ed28b">elpa_solve_evp_real_single</a> (int na, int nev, float *a, int lda, float *ev, float *q, int ldq, int nblk, int matrixCols, int mpi_comm_rows, int mpi_comm_cols, int mpi_comm_all, int THIS_REAL_ELPA_KERNEL_API, int useQR, int useGPU, char *method)</td></tr>
<tr class="memdesc:a6333453aa7a2cc6735b96d0a421ed28b"><td class="mdescLeft">&#160;</td><td class="mdescRight">C interface to driver function "elpa_solve_evp_real_single".  <a href="#a6333453aa7a2cc6735b96d0a421ed28b">More...</a><br /></td></tr>
<tr class="separator:a6333453aa7a2cc6735b96d0a421ed28b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7b353bd9a30fad467a18d0c0145ca977"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d2/da7/elpa_8h.html#a7b353bd9a30fad467a18d0c0145ca977">elpa_solve_evp_complex_double</a> (int na, int nev, std::complex&lt; double &gt; *a, int lda, double *ev, std::complex&lt; double &gt; *q, int ldq, int nblk, int matrixCols, int mpi_comm_rows, int mpi_comm_cols, int mpi_comm_all, int THIS_COMPLEX_ELPA_KERNEL_API, int useGPU, char *method)</td></tr>
<tr class="memdesc:a7b353bd9a30fad467a18d0c0145ca977"><td class="mdescLeft">&#160;</td><td class="mdescRight">C interface to driver function "elpa_solve_evp_complex_double".  <a href="#a7b353bd9a30fad467a18d0c0145ca977">More...</a><br /></td></tr>
<tr class="separator:a7b353bd9a30fad467a18d0c0145ca977"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad5fa0c790a1746cb5698f20d68d962ab"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d2/da7/elpa_8h.html#ad5fa0c790a1746cb5698f20d68d962ab">elpa_solve_evp_complex_single</a> (int na, int nev, std::complex&lt; float &gt; *a, int lda, float *ev, std::complex&lt; float &gt; *q, int ldq, int nblk, int matrixCols, int mpi_comm_rows, int mpi_comm_cols, int mpi_comm_all, int THIS_COMPLEX_ELPA_KERNEL_API, int useGPU, char *method)</td></tr>
<tr class="memdesc:ad5fa0c790a1746cb5698f20d68d962ab"><td class="mdescLeft">&#160;</td><td class="mdescRight">C interface to driver function "elpa_solve_evp_complex_single".  <a href="#ad5fa0c790a1746cb5698f20d68d962ab">More...</a><br /></td></tr>
<tr class="separator:ad5fa0c790a1746cb5698f20d68d962ab"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6b04db0f0c76607de1ad4cd246a5332e"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d2/da7/elpa_8h.html#a6b04db0f0c76607de1ad4cd246a5332e">get_elpa_row_col_comms</a> (int mpi_comm_world, int my_prow, int my_pcol, int *mpi_comm_rows, int *mpi_comm_cols)</td></tr>
<tr class="memdesc:a6b04db0f0c76607de1ad4cd246a5332e"><td class="mdescLeft">&#160;</td><td class="mdescRight">C old, deprecated interface, will be deleted. Use "elpa_get_communicators".  <a href="#a6b04db0f0c76607de1ad4cd246a5332e">More...</a><br /></td></tr>
<tr class="separator:a6b04db0f0c76607de1ad4cd246a5332e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4e650cee7b7534c031d65155bd039a18"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d2/da7/elpa_8h.html#a4e650cee7b7534c031d65155bd039a18">get_elpa_communicators</a> (int mpi_comm_world, int my_prow, int my_pcol, int *mpi_comm_rows, int *mpi_comm_cols)</td></tr>
<tr class="memdesc:a4e650cee7b7534c031d65155bd039a18"><td class="mdescLeft">&#160;</td><td class="mdescRight">C old, deprecated interface, will be deleted. Use "elpa_get_communicators".  <a href="#a4e650cee7b7534c031d65155bd039a18">More...</a><br /></td></tr>
<tr class="separator:a4e650cee7b7534c031d65155bd039a18"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afd6028eb5e4055f1ca5cc25de7e31ff4"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d2/da7/elpa_8h.html#afd6028eb5e4055f1ca5cc25de7e31ff4">elpa_get_communicators</a> (int mpi_comm_world, int my_prow, int my_pcol, int *mpi_comm_rows, int *mpi_comm_cols)</td></tr>
<tr class="memdesc:afd6028eb5e4055f1ca5cc25de7e31ff4"><td class="mdescLeft">&#160;</td><td class="mdescRight">C interface to create ELPA communicators.  <a href="#afd6028eb5e4055f1ca5cc25de7e31ff4">More...</a><br /></td></tr>
<tr class="separator:afd6028eb5e4055f1ca5cc25de7e31ff4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6487b99fa0c71c7c15603980aff3d945"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d2/da7/elpa_8h.html#a6487b99fa0c71c7c15603980aff3d945">elpa_solve_evp_real_1stage_double_precision</a> (int na, int nev, double *a, int lda, double *ev, double *q, int ldq, int nblk, int matrixCols, int mpi_comm_rows, int mpi_comm_cols, int mpi_comm_all, int useGPU)</td></tr>
<tr class="memdesc:a6487b99fa0c71c7c15603980aff3d945"><td class="mdescLeft">&#160;</td><td class="mdescRight">C interface to solve the double-precision real eigenvalue problem with 1-stage solver.  <a href="#a6487b99fa0c71c7c15603980aff3d945">More...</a><br /></td></tr>
<tr class="separator:a6487b99fa0c71c7c15603980aff3d945"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae2a716166d2517b508ac521528d8c0c3"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d2/da7/elpa_8h.html#ae2a716166d2517b508ac521528d8c0c3">elpa_solve_evp_real_1stage_single_precision</a> (int na, int nev, float *a, int lda, float *ev, float *q, int ldq, int nblk, int matrixCols, int mpi_comm_rows, int mpi_comm_cols, int mpi_comm_all, int useGPU)</td></tr>
<tr class="memdesc:ae2a716166d2517b508ac521528d8c0c3"><td class="mdescLeft">&#160;</td><td class="mdescRight">C interface to solve the single-precision real eigenvalue problem with 1-stage solver.  <a href="#ae2a716166d2517b508ac521528d8c0c3">More...</a><br /></td></tr>
<tr class="separator:ae2a716166d2517b508ac521528d8c0c3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a62d961698bf749d40838bf95f23772bc"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d2/da7/elpa_8h.html#a62d961698bf749d40838bf95f23772bc">elpa_solve_evp_complex_1stage_double_precision</a> (int na, int nev, std::complex&lt; double &gt; *a, int lda, double *ev, std::complex&lt; double &gt; *q, int ldq, int nblk, int matrixCols, int mpi_comm_rows, int mpi_comm_cols, int mpi_comm_all, int useGPU)</td></tr>
<tr class="memdesc:a62d961698bf749d40838bf95f23772bc"><td class="mdescLeft">&#160;</td><td class="mdescRight">C interface to solve the double-precision complex eigenvalue problem with 1-stage solver.  <a href="#a62d961698bf749d40838bf95f23772bc">More...</a><br /></td></tr>
<tr class="separator:a62d961698bf749d40838bf95f23772bc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0c06910e2c92e6a5d7a04369dd1f856e"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d2/da7/elpa_8h.html#a0c06910e2c92e6a5d7a04369dd1f856e">elpa_solve_evp_complex_1stage_single_precision</a> (int na, int nev, std::complex&lt; float &gt; *a, int lda, float *ev, std::complex&lt; float &gt; *q, int ldq, int nblk, int matrixCols, int mpi_comm_rows, int mpi_comm_cols, int mpi_comm_all, int useGPU)</td></tr>
<tr class="memdesc:a0c06910e2c92e6a5d7a04369dd1f856e"><td class="mdescLeft">&#160;</td><td class="mdescRight">C interface to solve the single-precision complex eigenvalue problem with 1-stage solver.  <a href="#a0c06910e2c92e6a5d7a04369dd1f856e">More...</a><br /></td></tr>
<tr class="separator:a0c06910e2c92e6a5d7a04369dd1f856e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4865098c1af64b0a2eccf86a4e91ec28"><td class="memItemLeft" align="right" valign="top"><a id="a4865098c1af64b0a2eccf86a4e91ec28"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>elpa_solve_tridi_double</b> (int na, int nev, double *d, double *e, double *q, int ldq, int nblk, int matrixCols, int mpi_comm_rows, int mpi_comm_cols, int wantDebug)</td></tr>
<tr class="separator:a4865098c1af64b0a2eccf86a4e91ec28"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aff710a3fef2710825f5f68fb7fc64bf1"><td class="memItemLeft" align="right" valign="top"><a id="aff710a3fef2710825f5f68fb7fc64bf1"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>elpa_solve_tridi_single</b> (int na, int nev, float *d, float *e, float *q, int ldq, int nblk, int matrixCols, int mpi_comm_rows, int mpi_comm_cols, int wantDebug)</td></tr>
<tr class="separator:aff710a3fef2710825f5f68fb7fc64bf1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afa36a7d8f2a4c75b3aa7f482abc74f0c"><td class="memItemLeft" align="right" valign="top"><a id="afa36a7d8f2a4c75b3aa7f482abc74f0c"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>elpa_mult_at_b_real_double</b> (char uplo_a, char uplo_c, int na, int ncb, double *a, int lda, int ldaCols, double *b, int ldb, int ldbCols, int nlbk, int mpi_comm_rows, int mpi_comm_cols, double *c, int ldc, int ldcCols)</td></tr>
<tr class="separator:afa36a7d8f2a4c75b3aa7f482abc74f0c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad0d56d03c50bab6eb204382979b0b512"><td class="memItemLeft" align="right" valign="top"><a id="ad0d56d03c50bab6eb204382979b0b512"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>elpa_mult_at_b_real_single</b> (char uplo_a, char uplo_c, int na, int ncb, float *a, int lda, int ldaCols, float *b, int ldb, int ldbCols, int nlbk, int mpi_comm_rows, int mpi_comm_cols, float *c, int ldc, int ldcCols)</td></tr>
<tr class="separator:ad0d56d03c50bab6eb204382979b0b512"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5cd47cc78c3d533fc1f9d5573b36c600"><td class="memItemLeft" align="right" valign="top"><a id="a5cd47cc78c3d533fc1f9d5573b36c600"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>elpa_mult_ah_b_complex_double</b> (char uplo_a, char uplo_c, int na, int ncb, std::complex&lt; double &gt; *a, int lda, int ldaCols, std::complex&lt; double &gt; *b, int ldb, int ldbCols, int nblk, int mpi_comm_rows, int mpi_comm_cols, std::complex&lt; double &gt; *c, int ldc, int ldcCols)</td></tr>
<tr class="separator:a5cd47cc78c3d533fc1f9d5573b36c600"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8e6bd3b7f7a44d340ec6cb65da21e67b"><td class="memItemLeft" align="right" valign="top"><a id="a8e6bd3b7f7a44d340ec6cb65da21e67b"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>elpa_mult_ah_b_complex_single</b> (char uplo_a, char uplo_c, int na, int ncb, std::complex&lt; float &gt; *a, int lda, int ldaCols, std::complex&lt; float &gt; *b, int ldb, int ldbCols, int nblk, int mpi_comm_rows, int mpi_comm_cols, std::complex&lt; float &gt; *c, int ldc, int ldcCols)</td></tr>
<tr class="separator:a8e6bd3b7f7a44d340ec6cb65da21e67b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7f618641f8eb8cc1827f2c2b2765adb6"><td class="memItemLeft" align="right" valign="top"><a id="a7f618641f8eb8cc1827f2c2b2765adb6"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>elpa_invert_trm_real_double</b> (int na, double *a, int lda, int nblk, int matrixCols, int mpi_comm_rows, int mpi_comm_cols, int wantDebug)</td></tr>
<tr class="separator:a7f618641f8eb8cc1827f2c2b2765adb6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a61f5cce5305e70d7909edda7e2c83c27"><td class="memItemLeft" align="right" valign="top"><a id="a61f5cce5305e70d7909edda7e2c83c27"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>elpa_invert_trm_real_single</b> (int na, double *a, int lda, int nblk, int matrixCols, int mpi_comm_rows, int mpi_comm_cols, int wantDebug)</td></tr>
<tr class="separator:a61f5cce5305e70d7909edda7e2c83c27"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1139527b10b30d59f4d973877528f094"><td class="memItemLeft" align="right" valign="top"><a id="a1139527b10b30d59f4d973877528f094"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>elpa_invert_trm_complex_double</b> (int na, std::complex&lt; double &gt; *a, int lda, int nblk, int matrixCols, int mpi_comm_rows, int mpi_comm_cols, int wantDebug)</td></tr>
<tr class="separator:a1139527b10b30d59f4d973877528f094"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a560534c9fca97a486d29c509f7c11915"><td class="memItemLeft" align="right" valign="top"><a id="a560534c9fca97a486d29c509f7c11915"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>elpa_invert_trm_complex_single</b> (int na, std::complex&lt; float &gt; *a, int lda, int nblk, int matrixCols, int mpi_comm_rows, int mpi_comm_cols, int wantDebug)</td></tr>
<tr class="separator:a560534c9fca97a486d29c509f7c11915"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a085a6315dffa38585e2c953b71a4d64f"><td class="memItemLeft" align="right" valign="top"><a id="a085a6315dffa38585e2c953b71a4d64f"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>elpa_cholesky_real_double</b> (int na, double *a, int lda, int nblk, int matrixCols, int mpi_comm_rows, int mpi_comm_cols, int wantDebug)</td></tr>
<tr class="separator:a085a6315dffa38585e2c953b71a4d64f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2d9ef65cfe4f981be1b0fa9681d4b984"><td class="memItemLeft" align="right" valign="top"><a id="a2d9ef65cfe4f981be1b0fa9681d4b984"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>elpa_cholesky_real_single</b> (int na, float *a, int lda, int nblk, int matrixCols, int mpi_comm_rows, int mpi_comm_cols, int wantDebug)</td></tr>
<tr class="separator:a2d9ef65cfe4f981be1b0fa9681d4b984"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acae8d54f2ab6acda2416d3569c484e75"><td class="memItemLeft" align="right" valign="top"><a id="acae8d54f2ab6acda2416d3569c484e75"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>elpa_cholesky_complex_double</b> (int na, std::complex&lt; double &gt; *a, int lda, int nblk, int matrixCols, int mpi_comm_rows, int mpi_comm_cols, int wantDebug)</td></tr>
<tr class="separator:acae8d54f2ab6acda2416d3569c484e75"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8b09e4b0511d30f82a5e5b505d65602d"><td class="memItemLeft" align="right" valign="top"><a id="a8b09e4b0511d30f82a5e5b505d65602d"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>elpa_cholesky_complex_single</b> (int na, std::complex&lt; float &gt; *a, int lda, int nblk, int matrixCols, int mpi_comm_rows, int mpi_comm_cols, int wantDebug)</td></tr>
<tr class="separator:a8b09e4b0511d30f82a5e5b505d65602d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aae26bb61962e2e45d6fe0a13c96e56a3"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d2/da7/elpa_8h.html#aae26bb61962e2e45d6fe0a13c96e56a3">elpa_solve_evp_real_2stage_double_precision</a> (int na, int nev, double *a, int lda, double *ev, double *q, int ldq, int nblk, int matrixCols, int mpi_comm_rows, int mpi_comm_cols, int mpi_comm_all, int THIS_REAL_ELPA_KERNEL_API, int useQR, int useGPU)</td></tr>
<tr class="memdesc:aae26bb61962e2e45d6fe0a13c96e56a3"><td class="mdescLeft">&#160;</td><td class="mdescRight">C interface to solve the double-precision real eigenvalue problem with 2-stage solver.  <a href="#aae26bb61962e2e45d6fe0a13c96e56a3">More...</a><br /></td></tr>
<tr class="separator:aae26bb61962e2e45d6fe0a13c96e56a3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a34cfca42f266e068879e21665a1bf55c"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d2/da7/elpa_8h.html#a34cfca42f266e068879e21665a1bf55c">elpa_solve_evp_real_2stage_single_precision</a> (int na, int nev, float *a, int lda, float *ev, float *q, int ldq, int nblk, int matrixCols, int mpi_comm_rows, int mpi_comm_cols, int mpi_comm_all, int THIS_REAL_ELPA_KERNEL_API, int useQR, int useGPU)</td></tr>
<tr class="memdesc:a34cfca42f266e068879e21665a1bf55c"><td class="mdescLeft">&#160;</td><td class="mdescRight">C interface to solve the single-precision real eigenvalue problem with 2-stage solver.  <a href="#a34cfca42f266e068879e21665a1bf55c">More...</a><br /></td></tr>
<tr class="separator:a34cfca42f266e068879e21665a1bf55c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1bc06b323973812e2ef19b8ffe1e9927"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d2/da7/elpa_8h.html#a1bc06b323973812e2ef19b8ffe1e9927">elpa_solve_evp_complex_2stage_double_precision</a> (int na, int nev, std::complex&lt; double &gt; *a, int lda, double *ev, std::complex&lt; double &gt; *q, int ldq, int nblk, int matrixCols, int mpi_comm_rows, int mpi_comm_cols, int mpi_comm_all, int THIS_COMPLEX_ELPA_KERNEL_API, int useGPU)</td></tr>
<tr class="memdesc:a1bc06b323973812e2ef19b8ffe1e9927"><td class="mdescLeft">&#160;</td><td class="mdescRight">C interface to solve the double-precision complex eigenvalue problem with 2-stage solver.  <a href="#a1bc06b323973812e2ef19b8ffe1e9927">More...</a><br /></td></tr>
<tr class="separator:a1bc06b323973812e2ef19b8ffe1e9927"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7ad732e2961fd8d141e2017d2622c1f4"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d2/da7/elpa_8h.html#a7ad732e2961fd8d141e2017d2622c1f4">elpa_solve_evp_complex_2stage_single_precision</a> (int na, int nev, std::complex&lt; float &gt; *a, int lda, float *ev, std::complex&lt; float &gt; *q, int ldq, int nblk, int matrixCols, int mpi_comm_rows, int mpi_comm_cols, int mpi_comm_all, int THIS_COMPLEX_ELPA_KERNEL_API, int useGPU)</td></tr>
<tr class="memdesc:a7ad732e2961fd8d141e2017d2622c1f4"><td class="mdescLeft">&#160;</td><td class="mdescRight">C interface to solve the single-precision complex eigenvalue problem with 2-stage solver.  <a href="#a7ad732e2961fd8d141e2017d2622c1f4">More...</a><br /></td></tr>
<tr class="separator:a7ad732e2961fd8d141e2017d2622c1f4"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>Interface to ELPA library. </p>

<p class="definition">Definition in file <a class="el" href="../../d2/da7/elpa_8h_source.html">elpa.h</a>.</p>
</div><h2 class="groupheader">Function Documentation</h2>
<a id="a350ad60d14a1858f99cf6825c5c3351a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a350ad60d14a1858f99cf6825c5c3351a">&#9670;&nbsp;</a></span>elpa_solve_evp_real_double()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int elpa_solve_evp_real_double </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>na</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nev</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double *&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>lda</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double *&#160;</td>
          <td class="paramname"><em>ev</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double *&#160;</td>
          <td class="paramname"><em>q</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>ldq</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nblk</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>matrixCols</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mpi_comm_rows</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mpi_comm_cols</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mpi_comm_all</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>THIS_REAL_ELPA_KERNEL_API</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>useQR</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>useGPU</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">char *&#160;</td>
          <td class="paramname"><em>method</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>C interface to driver function "elpa_solve_evp_real_double". </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">na</td><td>Order of matrix a </td></tr>
    <tr><td class="paramname">nev</td><td>Number of eigenvalues needed. The smallest nev eigenvalues/eigenvectors are calculated. </td></tr>
    <tr><td class="paramname">a</td><td>Distributed matrix for which eigenvalues are to be computed. Distribution is like in Scalapack. The full matrix must be set (not only one half like in scalapack). </td></tr>
    <tr><td class="paramname">lda</td><td>Leading dimension of a </td></tr>
    <tr><td class="paramname">ev(na)</td><td>On output: eigenvalues of a, every processor gets the complete set </td></tr>
    <tr><td class="paramname">q</td><td>On output: Eigenvectors of a Distribution is like in Scalapack. Must be always dimensioned to the full size (corresponding to (na,na)) even if only a part of the eigenvalues is needed. </td></tr>
    <tr><td class="paramname">ldq</td><td>Leading dimension of q </td></tr>
    <tr><td class="paramname">nblk</td><td>blocksize of cyclic distribution, must be the same in both directions! </td></tr>
    <tr><td class="paramname">matrixCols</td><td>distributed number of matrix columns </td></tr>
    <tr><td class="paramname">mpi_comm_rows</td><td>MPI-Communicator for rows </td></tr>
    <tr><td class="paramname">mpi_comm_cols</td><td>MPI-Communicator for columns </td></tr>
    <tr><td class="paramname">mpi_coll_all</td><td>MPI communicator for the total processor set </td></tr>
    <tr><td class="paramname">THIS_REAL_ELPA_KERNEL_API</td><td>specify used ELPA2 kernel via API </td></tr>
    <tr><td class="paramname">useQR</td><td>use QR decomposition 1 = yes, 0 = no </td></tr>
    <tr><td class="paramname">useGPU</td><td>use GPU (1=yes, 0=No) </td></tr>
    <tr><td class="paramname">method</td><td>choose whether to use ELPA 1stage or 2stage solver possible values: "1stage" =&gt; use ELPA 1stage solver "2stage" =&gt; use ELPA 2stage solver "auto" =&gt; (at the moment) use ELPA 2stage solver</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>int: 1 if error occured, otherwise 0 </dd></dl>

</div>
</div>
<a id="a6333453aa7a2cc6735b96d0a421ed28b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6333453aa7a2cc6735b96d0a421ed28b">&#9670;&nbsp;</a></span>elpa_solve_evp_real_single()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int elpa_solve_evp_real_single </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>na</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nev</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>lda</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&#160;</td>
          <td class="paramname"><em>ev</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&#160;</td>
          <td class="paramname"><em>q</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>ldq</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nblk</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>matrixCols</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mpi_comm_rows</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mpi_comm_cols</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mpi_comm_all</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>THIS_REAL_ELPA_KERNEL_API</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>useQR</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>useGPU</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">char *&#160;</td>
          <td class="paramname"><em>method</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>C interface to driver function "elpa_solve_evp_real_single". </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">na</td><td>Order of matrix a </td></tr>
    <tr><td class="paramname">nev</td><td>Number of eigenvalues needed. The smallest nev eigenvalues/eigenvectors are calculated. </td></tr>
    <tr><td class="paramname">a</td><td>Distributed matrix for which eigenvalues are to be computed. Distribution is like in Scalapack. The full matrix must be set (not only one half like in scalapack). </td></tr>
    <tr><td class="paramname">lda</td><td>Leading dimension of a </td></tr>
    <tr><td class="paramname">ev(na)</td><td>On output: eigenvalues of a, every processor gets the complete set </td></tr>
    <tr><td class="paramname">q</td><td>On output: Eigenvectors of a Distribution is like in Scalapack. Must be always dimensioned to the full size (corresponding to (na,na)) even if only a part of the eigenvalues is needed. </td></tr>
    <tr><td class="paramname">ldq</td><td>Leading dimension of q </td></tr>
    <tr><td class="paramname">nblk</td><td>blocksize of cyclic distribution, must be the same in both directions! </td></tr>
    <tr><td class="paramname">matrixCols</td><td>distributed number of matrix columns </td></tr>
    <tr><td class="paramname">mpi_comm_rows</td><td>MPI-Communicator for rows </td></tr>
    <tr><td class="paramname">mpi_comm_cols</td><td>MPI-Communicator for columns </td></tr>
    <tr><td class="paramname">mpi_coll_all</td><td>MPI communicator for the total processor set </td></tr>
    <tr><td class="paramname">THIS_REAL_ELPA_KERNEL_API</td><td>specify used ELPA2 kernel via API </td></tr>
    <tr><td class="paramname">useQR</td><td>use QR decomposition 1 = yes, 0 = no </td></tr>
    <tr><td class="paramname">useGPU</td><td>use GPU (1=yes, 0=No) </td></tr>
    <tr><td class="paramname">method</td><td>choose whether to use ELPA 1stage or 2stage solver possible values: "1stage" =&gt; use ELPA 1stage solver "2stage" =&gt; use ELPA 2stage solver "auto" =&gt; (at the moment) use ELPA 2stage solver</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>int: 1 if error occured, otherwise 0 </dd></dl>

</div>
</div>
<a id="a7b353bd9a30fad467a18d0c0145ca977"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7b353bd9a30fad467a18d0c0145ca977">&#9670;&nbsp;</a></span>elpa_solve_evp_complex_double()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int elpa_solve_evp_complex_double </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>na</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nev</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::complex&lt; double &gt; *&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>lda</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double *&#160;</td>
          <td class="paramname"><em>ev</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::complex&lt; double &gt; *&#160;</td>
          <td class="paramname"><em>q</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>ldq</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nblk</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>matrixCols</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mpi_comm_rows</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mpi_comm_cols</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mpi_comm_all</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>THIS_COMPLEX_ELPA_KERNEL_API</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>useGPU</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">char *&#160;</td>
          <td class="paramname"><em>method</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>C interface to driver function "elpa_solve_evp_complex_double". </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">na</td><td>Order of matrix a </td></tr>
    <tr><td class="paramname">nev</td><td>Number of eigenvalues needed. The smallest nev eigenvalues/eigenvectors are calculated. </td></tr>
    <tr><td class="paramname">a</td><td>Distributed matrix for which eigenvalues are to be computed. Distribution is like in Scalapack. The full matrix must be set (not only one half like in scalapack). </td></tr>
    <tr><td class="paramname">lda</td><td>Leading dimension of a </td></tr>
    <tr><td class="paramname">ev(na)</td><td>On output: eigenvalues of a, every processor gets the complete set </td></tr>
    <tr><td class="paramname">q</td><td>On output: Eigenvectors of a Distribution is like in Scalapack. Must be always dimensioned to the full size (corresponding to (na,na)) even if only a part of the eigenvalues is needed. </td></tr>
    <tr><td class="paramname">ldq</td><td>Leading dimension of q </td></tr>
    <tr><td class="paramname">nblk</td><td>blocksize of cyclic distribution, must be the same in both directions! </td></tr>
    <tr><td class="paramname">matrixCols</td><td>distributed number of matrix columns </td></tr>
    <tr><td class="paramname">mpi_comm_rows</td><td>MPI-Communicator for rows </td></tr>
    <tr><td class="paramname">mpi_comm_cols</td><td>MPI-Communicator for columns </td></tr>
    <tr><td class="paramname">mpi_coll_all</td><td>MPI communicator for the total processor set </td></tr>
    <tr><td class="paramname">THIS_COMPLEX_ELPA_KERNEL_API</td><td>specify used ELPA2 kernel via API </td></tr>
    <tr><td class="paramname">useGPU</td><td>use GPU (1=yes, 0=No) </td></tr>
    <tr><td class="paramname">method</td><td>choose whether to use ELPA 1stage or 2stage solver possible values: "1stage" =&gt; use ELPA 1stage solver "2stage" =&gt; use ELPA 2stage solver "auto" =&gt; (at the moment) use ELPA 2stage solver</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>int: 1 if error occured, otherwise 0 </dd></dl>

</div>
</div>
<a id="ad5fa0c790a1746cb5698f20d68d962ab"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad5fa0c790a1746cb5698f20d68d962ab">&#9670;&nbsp;</a></span>elpa_solve_evp_complex_single()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int elpa_solve_evp_complex_single </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>na</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nev</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::complex&lt; float &gt; *&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>lda</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&#160;</td>
          <td class="paramname"><em>ev</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::complex&lt; float &gt; *&#160;</td>
          <td class="paramname"><em>q</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>ldq</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nblk</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>matrixCols</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mpi_comm_rows</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mpi_comm_cols</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mpi_comm_all</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>THIS_COMPLEX_ELPA_KERNEL_API</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>useGPU</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">char *&#160;</td>
          <td class="paramname"><em>method</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>C interface to driver function "elpa_solve_evp_complex_single". </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">na</td><td>Order of matrix a </td></tr>
    <tr><td class="paramname">nev</td><td>Number of eigenvalues needed. The smallest nev eigenvalues/eigenvectors are calculated. </td></tr>
    <tr><td class="paramname">a</td><td>Distributed matrix for which eigenvalues are to be computed. Distribution is like in Scalapack. The full matrix must be set (not only one half like in scalapack). </td></tr>
    <tr><td class="paramname">lda</td><td>Leading dimension of a </td></tr>
    <tr><td class="paramname">ev(na)</td><td>On output: eigenvalues of a, every processor gets the complete set </td></tr>
    <tr><td class="paramname">q</td><td>On output: Eigenvectors of a Distribution is like in Scalapack. Must be always dimensioned to the full size (corresponding to (na,na)) even if only a part of the eigenvalues is needed. </td></tr>
    <tr><td class="paramname">ldq</td><td>Leading dimension of q </td></tr>
    <tr><td class="paramname">nblk</td><td>blocksize of cyclic distribution, must be the same in both directions! </td></tr>
    <tr><td class="paramname">matrixCols</td><td>distributed number of matrix columns </td></tr>
    <tr><td class="paramname">mpi_comm_rows</td><td>MPI-Communicator for rows </td></tr>
    <tr><td class="paramname">mpi_comm_cols</td><td>MPI-Communicator for columns </td></tr>
    <tr><td class="paramname">mpi_coll_all</td><td>MPI communicator for the total processor set </td></tr>
    <tr><td class="paramname">THIS_COMPLEX_ELPA_KERNEL_API</td><td>specify used ELPA2 kernel via API </td></tr>
    <tr><td class="paramname">useGPU</td><td>use GPU (1=yes, 0=No) </td></tr>
    <tr><td class="paramname">method</td><td>choose whether to use ELPA 1stage or 2stage solver possible values: "1stage" =&gt; use ELPA 1stage solver "2stage" =&gt; use ELPA 2stage solver "auto" =&gt; (at the moment) use ELPA 2stage solver</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>int: 1 if error occured, otherwise 0 </dd></dl>

</div>
</div>
<a id="a6b04db0f0c76607de1ad4cd246a5332e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6b04db0f0c76607de1ad4cd246a5332e">&#9670;&nbsp;</a></span>get_elpa_row_col_comms()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int get_elpa_row_col_comms </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mpi_comm_world</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>my_prow</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>my_pcol</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int *&#160;</td>
          <td class="paramname"><em>mpi_comm_rows</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int *&#160;</td>
          <td class="paramname"><em>mpi_comm_cols</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>C old, deprecated interface, will be deleted. Use "elpa_get_communicators". </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">mpi_comm_word</td><td>MPI global communicator (in) </td></tr>
    <tr><td class="paramname">my_prow</td><td>Row coordinate of the calling process in the process grid (in) </td></tr>
    <tr><td class="paramname">my_pcol</td><td>Column coordinate of the calling process in the process grid (in) </td></tr>
    <tr><td class="paramname">mpi_comm_rows</td><td>Communicator for communicating within rows of processes (out) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>int integer error value of mpi_comm_split function </dd></dl>

</div>
</div>
<a id="a4e650cee7b7534c031d65155bd039a18"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4e650cee7b7534c031d65155bd039a18">&#9670;&nbsp;</a></span>get_elpa_communicators()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int get_elpa_communicators </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mpi_comm_world</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>my_prow</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>my_pcol</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int *&#160;</td>
          <td class="paramname"><em>mpi_comm_rows</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int *&#160;</td>
          <td class="paramname"><em>mpi_comm_cols</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>C old, deprecated interface, will be deleted. Use "elpa_get_communicators". </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">mpi_comm_word</td><td>MPI global communicator (in) </td></tr>
    <tr><td class="paramname">my_prow</td><td>Row coordinate of the calling process in the process grid (in) </td></tr>
    <tr><td class="paramname">my_pcol</td><td>Column coordinate of the calling process in the process grid (in) </td></tr>
    <tr><td class="paramname">mpi_comm_rows</td><td>Communicator for communicating within rows of processes (out) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>int integer error value of mpi_comm_split function </dd></dl>

</div>
</div>
<a id="afd6028eb5e4055f1ca5cc25de7e31ff4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afd6028eb5e4055f1ca5cc25de7e31ff4">&#9670;&nbsp;</a></span>elpa_get_communicators()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int elpa_get_communicators </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mpi_comm_world</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>my_prow</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>my_pcol</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int *&#160;</td>
          <td class="paramname"><em>mpi_comm_rows</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int *&#160;</td>
          <td class="paramname"><em>mpi_comm_cols</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>C interface to create ELPA communicators. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">mpi_comm_word</td><td>MPI global communicator (in) </td></tr>
    <tr><td class="paramname">my_prow</td><td>Row coordinate of the calling process in the process grid (in) </td></tr>
    <tr><td class="paramname">my_pcol</td><td>Column coordinate of the calling process in the process grid (in) </td></tr>
    <tr><td class="paramname">mpi_comm_rows</td><td>Communicator for communicating within rows of processes (out) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>int integer error value of mpi_comm_split function </dd></dl>

</div>
</div>
<a id="a6487b99fa0c71c7c15603980aff3d945"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6487b99fa0c71c7c15603980aff3d945">&#9670;&nbsp;</a></span>elpa_solve_evp_real_1stage_double_precision()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int elpa_solve_evp_real_1stage_double_precision </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>na</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nev</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double *&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>lda</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double *&#160;</td>
          <td class="paramname"><em>ev</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double *&#160;</td>
          <td class="paramname"><em>q</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>ldq</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nblk</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>matrixCols</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mpi_comm_rows</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mpi_comm_cols</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mpi_comm_all</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>useGPU</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>C interface to solve the double-precision real eigenvalue problem with 1-stage solver. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">na</td><td>Order of matrix a </td></tr>
    <tr><td class="paramname">nev</td><td>Number of eigenvalues needed. The smallest nev eigenvalues/eigenvectors are calculated. </td></tr>
    <tr><td class="paramname">a</td><td>Distributed matrix for which eigenvalues are to be computed. Distribution is like in Scalapack. The full matrix must be set (not only one half like in scalapack). </td></tr>
    <tr><td class="paramname">lda</td><td>Leading dimension of a </td></tr>
    <tr><td class="paramname">ev(na)</td><td>On output: eigenvalues of a, every processor gets the complete set </td></tr>
    <tr><td class="paramname">q</td><td>On output: Eigenvectors of a Distribution is like in Scalapack. Must be always dimensioned to the full size (corresponding to (na,na)) even if only a part of the eigenvalues is needed. </td></tr>
    <tr><td class="paramname">ldq</td><td>Leading dimension of q </td></tr>
    <tr><td class="paramname">nblk</td><td>blocksize of cyclic distribution, must be the same in both directions! </td></tr>
    <tr><td class="paramname">matrixCols</td><td>distributed number of matrix columns </td></tr>
    <tr><td class="paramname">mpi_comm_rows</td><td>MPI-Communicator for rows </td></tr>
    <tr><td class="paramname">mpi_comm_cols</td><td>MPI-Communicator for columns </td></tr>
    <tr><td class="paramname">useGPU</td><td>use GPU (1=yes, 0=No)</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>int: 1 if error occured, otherwise 0 </dd></dl>

</div>
</div>
<a id="ae2a716166d2517b508ac521528d8c0c3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae2a716166d2517b508ac521528d8c0c3">&#9670;&nbsp;</a></span>elpa_solve_evp_real_1stage_single_precision()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int elpa_solve_evp_real_1stage_single_precision </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>na</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nev</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>lda</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&#160;</td>
          <td class="paramname"><em>ev</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&#160;</td>
          <td class="paramname"><em>q</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>ldq</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nblk</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>matrixCols</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mpi_comm_rows</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mpi_comm_cols</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mpi_comm_all</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>useGPU</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>C interface to solve the single-precision real eigenvalue problem with 1-stage solver. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">na</td><td>Order of matrix a </td></tr>
    <tr><td class="paramname">nev</td><td>Number of eigenvalues needed. The smallest nev eigenvalues/eigenvectors are calculated. </td></tr>
    <tr><td class="paramname">a</td><td>Distributed matrix for which eigenvalues are to be computed. Distribution is like in Scalapack. The full matrix must be set (not only one half like in scalapack). </td></tr>
    <tr><td class="paramname">lda</td><td>Leading dimension of a </td></tr>
    <tr><td class="paramname">ev(na)</td><td>On output: eigenvalues of a, every processor gets the complete set </td></tr>
    <tr><td class="paramname">q</td><td>On output: Eigenvectors of a Distribution is like in Scalapack. Must be always dimensioned to the full size (corresponding to (na,na)) even if only a part of the eigenvalues is needed. </td></tr>
    <tr><td class="paramname">ldq</td><td>Leading dimension of q </td></tr>
    <tr><td class="paramname">nblk</td><td>blocksize of cyclic distribution, must be the same in both directions! </td></tr>
    <tr><td class="paramname">matrixCols</td><td>distributed number of matrix columns </td></tr>
    <tr><td class="paramname">mpi_comm_rows</td><td>MPI-Communicator for rows </td></tr>
    <tr><td class="paramname">mpi_comm_cols</td><td>MPI-Communicator for columns </td></tr>
    <tr><td class="paramname">useGPU</td><td>use GPU (1=yes, 0=No)</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>int: 1 if error occured, otherwise 0 </dd></dl>

</div>
</div>
<a id="a62d961698bf749d40838bf95f23772bc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a62d961698bf749d40838bf95f23772bc">&#9670;&nbsp;</a></span>elpa_solve_evp_complex_1stage_double_precision()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int elpa_solve_evp_complex_1stage_double_precision </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>na</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nev</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::complex&lt; double &gt; *&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>lda</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double *&#160;</td>
          <td class="paramname"><em>ev</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::complex&lt; double &gt; *&#160;</td>
          <td class="paramname"><em>q</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>ldq</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nblk</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>matrixCols</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mpi_comm_rows</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mpi_comm_cols</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mpi_comm_all</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>useGPU</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>C interface to solve the double-precision complex eigenvalue problem with 1-stage solver. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">na</td><td>Order of matrix a </td></tr>
    <tr><td class="paramname">nev</td><td>Number of eigenvalues needed. The smallest nev eigenvalues/eigenvectors are calculated. </td></tr>
    <tr><td class="paramname">a</td><td>Distributed matrix for which eigenvalues are to be computed. Distribution is like in Scalapack. The full matrix must be set (not only one half like in scalapack). </td></tr>
    <tr><td class="paramname">lda</td><td>Leading dimension of a </td></tr>
    <tr><td class="paramname">ev(na)</td><td>On output: eigenvalues of a, every processor gets the complete set </td></tr>
    <tr><td class="paramname">q</td><td>On output: Eigenvectors of a Distribution is like in Scalapack. Must be always dimensioned to the full size (corresponding to (na,na)) even if only a part of the eigenvalues is needed. </td></tr>
    <tr><td class="paramname">ldq</td><td>Leading dimension of q </td></tr>
    <tr><td class="paramname">nblk</td><td>blocksize of cyclic distribution, must be the same in both directions! </td></tr>
    <tr><td class="paramname">matrixCols</td><td>distributed number of matrix columns </td></tr>
    <tr><td class="paramname">mpi_comm_rows</td><td>MPI-Communicator for rows </td></tr>
    <tr><td class="paramname">mpi_comm_cols</td><td>MPI-Communicator for columns </td></tr>
    <tr><td class="paramname">useGPU</td><td>use GPU (1=yes, 0=No)</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>int: 1 if error occured, otherwise 0 </dd></dl>

</div>
</div>
<a id="a0c06910e2c92e6a5d7a04369dd1f856e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0c06910e2c92e6a5d7a04369dd1f856e">&#9670;&nbsp;</a></span>elpa_solve_evp_complex_1stage_single_precision()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int elpa_solve_evp_complex_1stage_single_precision </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>na</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nev</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::complex&lt; float &gt; *&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>lda</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&#160;</td>
          <td class="paramname"><em>ev</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::complex&lt; float &gt; *&#160;</td>
          <td class="paramname"><em>q</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>ldq</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nblk</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>matrixCols</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mpi_comm_rows</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mpi_comm_cols</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mpi_comm_all</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>useGPU</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>C interface to solve the single-precision complex eigenvalue problem with 1-stage solver. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">na</td><td>Order of matrix a </td></tr>
    <tr><td class="paramname">nev</td><td>Number of eigenvalues needed. The smallest nev eigenvalues/eigenvectors are calculated. </td></tr>
    <tr><td class="paramname">a</td><td>Distributed matrix for which eigenvalues are to be computed. Distribution is like in Scalapack. The full matrix must be set (not only one half like in scalapack). </td></tr>
    <tr><td class="paramname">lda</td><td>Leading dimension of a </td></tr>
    <tr><td class="paramname">ev(na)</td><td>On output: eigenvalues of a, every processor gets the complete set </td></tr>
    <tr><td class="paramname">q</td><td>On output: Eigenvectors of a Distribution is like in Scalapack. Must be always dimensioned to the full size (corresponding to (na,na)) even if only a part of the eigenvalues is needed. </td></tr>
    <tr><td class="paramname">ldq</td><td>Leading dimension of q </td></tr>
    <tr><td class="paramname">nblk</td><td>blocksize of cyclic distribution, must be the same in both directions! </td></tr>
    <tr><td class="paramname">matrixCols</td><td>distributed number of matrix columns </td></tr>
    <tr><td class="paramname">mpi_comm_rows</td><td>MPI-Communicator for rows </td></tr>
    <tr><td class="paramname">mpi_comm_cols</td><td>MPI-Communicator for columns </td></tr>
    <tr><td class="paramname">useGPU</td><td>use GPU (1=yes, 0=No)</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>int: 1 if error occured, otherwise 0 </dd></dl>

</div>
</div>
<a id="aae26bb61962e2e45d6fe0a13c96e56a3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aae26bb61962e2e45d6fe0a13c96e56a3">&#9670;&nbsp;</a></span>elpa_solve_evp_real_2stage_double_precision()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int elpa_solve_evp_real_2stage_double_precision </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>na</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nev</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double *&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>lda</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double *&#160;</td>
          <td class="paramname"><em>ev</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double *&#160;</td>
          <td class="paramname"><em>q</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>ldq</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nblk</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>matrixCols</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mpi_comm_rows</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mpi_comm_cols</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mpi_comm_all</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>THIS_REAL_ELPA_KERNEL_API</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>useQR</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>useGPU</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>C interface to solve the double-precision real eigenvalue problem with 2-stage solver. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">na</td><td>Order of matrix a </td></tr>
    <tr><td class="paramname">nev</td><td>Number of eigenvalues needed. The smallest nev eigenvalues/eigenvectors are calculated. </td></tr>
    <tr><td class="paramname">a</td><td>Distributed matrix for which eigenvalues are to be computed. Distribution is like in Scalapack. The full matrix must be set (not only one half like in scalapack). </td></tr>
    <tr><td class="paramname">lda</td><td>Leading dimension of a </td></tr>
    <tr><td class="paramname">ev(na)</td><td>On output: eigenvalues of a, every processor gets the complete set </td></tr>
    <tr><td class="paramname">q</td><td>On output: Eigenvectors of a Distribution is like in Scalapack. Must be always dimensioned to the full size (corresponding to (na,na)) even if only a part of the eigenvalues is needed. </td></tr>
    <tr><td class="paramname">ldq</td><td>Leading dimension of q </td></tr>
    <tr><td class="paramname">nblk</td><td>blocksize of cyclic distribution, must be the same in both directions! </td></tr>
    <tr><td class="paramname">matrixCols</td><td>distributed number of matrix columns </td></tr>
    <tr><td class="paramname">mpi_comm_rows</td><td>MPI-Communicator for rows </td></tr>
    <tr><td class="paramname">mpi_comm_cols</td><td>MPI-Communicator for columns </td></tr>
    <tr><td class="paramname">mpi_coll_all</td><td>MPI communicator for the total processor set </td></tr>
    <tr><td class="paramname">THIS_REAL_ELPA_KERNEL_API</td><td>specify used ELPA2 kernel via API </td></tr>
    <tr><td class="paramname">useQR</td><td>use QR decomposition 1 = yes, 0 = no </td></tr>
    <tr><td class="paramname">useGPU</td><td>use GPU (1=yes, 0=No)</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>int: 1 if error occured, otherwise 0 </dd></dl>

</div>
</div>
<a id="a34cfca42f266e068879e21665a1bf55c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a34cfca42f266e068879e21665a1bf55c">&#9670;&nbsp;</a></span>elpa_solve_evp_real_2stage_single_precision()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int elpa_solve_evp_real_2stage_single_precision </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>na</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nev</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>lda</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&#160;</td>
          <td class="paramname"><em>ev</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&#160;</td>
          <td class="paramname"><em>q</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>ldq</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nblk</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>matrixCols</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mpi_comm_rows</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mpi_comm_cols</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mpi_comm_all</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>THIS_REAL_ELPA_KERNEL_API</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>useQR</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>useGPU</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>C interface to solve the single-precision real eigenvalue problem with 2-stage solver. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">na</td><td>Order of matrix a </td></tr>
    <tr><td class="paramname">nev</td><td>Number of eigenvalues needed. The smallest nev eigenvalues/eigenvectors are calculated. </td></tr>
    <tr><td class="paramname">a</td><td>Distributed matrix for which eigenvalues are to be computed. Distribution is like in Scalapack. The full matrix must be set (not only one half like in scalapack). </td></tr>
    <tr><td class="paramname">lda</td><td>Leading dimension of a </td></tr>
    <tr><td class="paramname">ev(na)</td><td>On output: eigenvalues of a, every processor gets the complete set </td></tr>
    <tr><td class="paramname">q</td><td>On output: Eigenvectors of a Distribution is like in Scalapack. Must be always dimensioned to the full size (corresponding to (na,na)) even if only a part of the eigenvalues is needed. </td></tr>
    <tr><td class="paramname">ldq</td><td>Leading dimension of q </td></tr>
    <tr><td class="paramname">nblk</td><td>blocksize of cyclic distribution, must be the same in both directions! </td></tr>
    <tr><td class="paramname">matrixCols</td><td>distributed number of matrix columns </td></tr>
    <tr><td class="paramname">mpi_comm_rows</td><td>MPI-Communicator for rows </td></tr>
    <tr><td class="paramname">mpi_comm_cols</td><td>MPI-Communicator for columns </td></tr>
    <tr><td class="paramname">mpi_coll_all</td><td>MPI communicator for the total processor set </td></tr>
    <tr><td class="paramname">THIS_REAL_ELPA_KERNEL_API</td><td>specify used ELPA2 kernel via API </td></tr>
    <tr><td class="paramname">useQR</td><td>use QR decomposition 1 = yes, 0 = no </td></tr>
    <tr><td class="paramname">useGPU</td><td>use GPU (1=yes, 0=No)</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>int: 1 if error occured, otherwise 0 </dd></dl>

</div>
</div>
<a id="a1bc06b323973812e2ef19b8ffe1e9927"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1bc06b323973812e2ef19b8ffe1e9927">&#9670;&nbsp;</a></span>elpa_solve_evp_complex_2stage_double_precision()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int elpa_solve_evp_complex_2stage_double_precision </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>na</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nev</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::complex&lt; double &gt; *&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>lda</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double *&#160;</td>
          <td class="paramname"><em>ev</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::complex&lt; double &gt; *&#160;</td>
          <td class="paramname"><em>q</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>ldq</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nblk</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>matrixCols</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mpi_comm_rows</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mpi_comm_cols</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mpi_comm_all</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>THIS_COMPLEX_ELPA_KERNEL_API</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>useGPU</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>C interface to solve the double-precision complex eigenvalue problem with 2-stage solver. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">na</td><td>Order of matrix a </td></tr>
    <tr><td class="paramname">nev</td><td>Number of eigenvalues needed. The smallest nev eigenvalues/eigenvectors are calculated. </td></tr>
    <tr><td class="paramname">a</td><td>Distributed matrix for which eigenvalues are to be computed. Distribution is like in Scalapack. The full matrix must be set (not only one half like in scalapack). </td></tr>
    <tr><td class="paramname">lda</td><td>Leading dimension of a </td></tr>
    <tr><td class="paramname">ev(na)</td><td>On output: eigenvalues of a, every processor gets the complete set </td></tr>
    <tr><td class="paramname">q</td><td>On output: Eigenvectors of a Distribution is like in Scalapack. Must be always dimensioned to the full size (corresponding to (na,na)) even if only a part of the eigenvalues is needed. </td></tr>
    <tr><td class="paramname">ldq</td><td>Leading dimension of q </td></tr>
    <tr><td class="paramname">nblk</td><td>blocksize of cyclic distribution, must be the same in both directions! </td></tr>
    <tr><td class="paramname">matrixCols</td><td>distributed number of matrix columns </td></tr>
    <tr><td class="paramname">mpi_comm_rows</td><td>MPI-Communicator for rows </td></tr>
    <tr><td class="paramname">mpi_comm_cols</td><td>MPI-Communicator for columns </td></tr>
    <tr><td class="paramname">mpi_coll_all</td><td>MPI communicator for the total processor set </td></tr>
    <tr><td class="paramname">THIS_COMPLEX_ELPA_KERNEL_API</td><td>specify used ELPA2 kernel via API </td></tr>
    <tr><td class="paramname">useGPU</td><td>use GPU (1=yes, 0=No)</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>int: 1 if error occured, otherwise 0 </dd></dl>

</div>
</div>
<a id="a7ad732e2961fd8d141e2017d2622c1f4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7ad732e2961fd8d141e2017d2622c1f4">&#9670;&nbsp;</a></span>elpa_solve_evp_complex_2stage_single_precision()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int elpa_solve_evp_complex_2stage_single_precision </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>na</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nev</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::complex&lt; float &gt; *&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>lda</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&#160;</td>
          <td class="paramname"><em>ev</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::complex&lt; float &gt; *&#160;</td>
          <td class="paramname"><em>q</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>ldq</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nblk</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>matrixCols</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mpi_comm_rows</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mpi_comm_cols</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>mpi_comm_all</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>THIS_COMPLEX_ELPA_KERNEL_API</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>useGPU</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>C interface to solve the single-precision complex eigenvalue problem with 2-stage solver. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">na</td><td>Order of matrix a </td></tr>
    <tr><td class="paramname">nev</td><td>Number of eigenvalues needed. The smallest nev eigenvalues/eigenvectors are calculated. </td></tr>
    <tr><td class="paramname">a</td><td>Distributed matrix for which eigenvalues are to be computed. Distribution is like in Scalapack. The full matrix must be set (not only one half like in scalapack). </td></tr>
    <tr><td class="paramname">lda</td><td>Leading dimension of a </td></tr>
    <tr><td class="paramname">ev(na)</td><td>On output: eigenvalues of a, every processor gets the complete set </td></tr>
    <tr><td class="paramname">q</td><td>On output: Eigenvectors of a Distribution is like in Scalapack. Must be always dimensioned to the full size (corresponding to (na,na)) even if only a part of the eigenvalues is needed. </td></tr>
    <tr><td class="paramname">ldq</td><td>Leading dimension of q </td></tr>
    <tr><td class="paramname">nblk</td><td>blocksize of cyclic distribution, must be the same in both directions! </td></tr>
    <tr><td class="paramname">matrixCols</td><td>distributed number of matrix columns </td></tr>
    <tr><td class="paramname">mpi_comm_rows</td><td>MPI-Communicator for rows </td></tr>
    <tr><td class="paramname">mpi_comm_cols</td><td>MPI-Communicator for columns </td></tr>
    <tr><td class="paramname">mpi_coll_all</td><td>MPI communicator for the total processor set </td></tr>
    <tr><td class="paramname">THIS_REAL_ELPA_KERNEL_API</td><td>specify used ELPA2 kernel via API </td></tr>
    <tr><td class="paramname">useGPU</td><td>use GPU (1=yes, 0=No)</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>int: 1 if error occured, otherwise 0 </dd></dl>

</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Fri Dec 21 2018 16:32:55 for SIRIUS by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="../../doxygen.png" alt="doxygen"/>
</a> 1.8.14
</small></address>
</body>
</html>
